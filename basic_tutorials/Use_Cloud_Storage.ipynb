{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "progressive-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-george",
   "metadata": {},
   "source": [
    "## Reading/Writing to Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solar-commander",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cbis-ddsm-png/\n",
      "gs://cbis-ddsm-test/\n",
      "gs://cbis-ddsm-train/\n",
      "gs://cbis_ddsm_raw/\n"
     ]
    }
   ],
   "source": [
    "project_id = \"final-307422\"\n",
    "!gsutil ls -p $project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "naked-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "responsible-certificate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket name: cbis-ddsm-train\n",
      "Bucket location: US\n",
      "Bucket storage class: STANDARD\n"
     ]
    }
   ],
   "source": [
    "mode='train'\n",
    "bucket_name = f'cbis-ddsm-{mode}'\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "print(\"Bucket name: {}\".format(bucket.name))\n",
    "print(\"Bucket location: {}\".format(bucket.location))\n",
    "print(\"Bucket storage class: {}\".format(bucket.storage_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-amsterdam",
   "metadata": {},
   "source": [
    "##### Listing files in our bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dedicated-companion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blobs in cbis-ddsm-train:\n"
     ]
    }
   ],
   "source": [
    "blobs = bucket.list_blobs()\n",
    "print(\"Blobs in {}:\".format(bucket.name))\n",
    "filepaths = []\n",
    "for item in blobs: filepaths.append(item.name)\n",
    "len(filepaths)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-texture",
   "metadata": {},
   "source": [
    "## Construct image path mappings from downloaded paths into that of label table's specified img paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.Series(filepaths,name='fullpath').str.strip().to_frame()\n",
    "\n",
    "fdf_parsed = pd.DataFrame.from_records(fdf.fullpath.apply(lambda x: x.split('/')),index=fdf.index)\n",
    "fdf_parsed.columns = ['patient_id','folder_1','folder_2','image_name']\n",
    "fdf = fdf.join(fdf_parsed)\n",
    "\n",
    "fdf['folder_1_last5'] = fdf['folder_1'].apply(lambda x: x[-5:])\n",
    "fdf['folder_2_last5'] = fdf['folder_2'].apply(lambda x: x[-5:])\n",
    "fdf['new_image_name'] = fdf.image_name.str.replace('1-1.dcm','000000.dcm').str.replace('1-2.dcm','000001.dcm')\n",
    "\n",
    "fdf['for_join'] = fdf.patient_id +'/'+ fdf.folder_1_last5 + '/' \\\n",
    "            + fdf.folder_2_last5 + '/' + fdf.new_image_name\n",
    "\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-building",
   "metadata": {},
   "source": [
    "Read file paths from label csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "light-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([pd.read_csv(f'metadata/calc_case_description_{mode}_set.csv'),\n",
    "                    pd.read_csv(f'metadata/mass_case_description_{mode}_set.csv')],ignore_index=True)\n",
    "\n",
    "old_img_filepath_parsed =  pd.DataFrame.from_records(labels['image file path'].str.strip().str.split('/'),index=labels.index)\n",
    "old_img_filepath_parsed.columns = ['patient_id','folder_1','folder_2','image_name']\n",
    "old_img_filepath_parsed = old_img_filepath_parsed.join(labels['image file path'].str.strip(),how='left')\n",
    "old_img_filepath_parsed = old_img_filepath_parsed.rename(columns={'image file path':'old_image_filepath'})\n",
    "\n",
    "old_crop_filepath_parsed =  pd.DataFrame.from_records(labels['cropped image file path'].str.strip().str.split('/'),index=labels.index)\n",
    "old_crop_filepath_parsed.columns = ['patient_id','folder_1','folder_2','image_name']\n",
    "old_crop_filepath_parsed = old_crop_filepath_parsed.join(labels['cropped image file path'].str.strip(),how='left')\n",
    "old_crop_filepath_parsed = old_crop_filepath_parsed.rename(columns={'cropped image file path':'old_image_filepath'})\n",
    "\n",
    "old_roi_filepath_parsed =  pd.DataFrame.from_records(labels['ROI mask file path'].str.strip().str.split('/'),index=labels.index)\n",
    "old_roi_filepath_parsed.columns = ['patient_id','folder_1','folder_2','image_name']\n",
    "old_roi_filepath_parsed = old_roi_filepath_parsed.join(labels['ROI mask file path'].str.strip(),how='left')\n",
    "old_roi_filepath_parsed = old_roi_filepath_parsed.rename(columns={'ROI mask file path':'old_image_filepath'})\n",
    "\n",
    "old_parsed = pd.concat([old_img_filepath_parsed,old_crop_filepath_parsed,old_roi_filepath_parsed],ignore_index=True)\n",
    "\n",
    "old_parsed['folder_1_last5'] = old_parsed['folder_1'].apply(lambda x: x[-5:])\n",
    "old_parsed['folder_2_last5'] = old_parsed['folder_2'].apply(lambda x: x[-5:])\n",
    "\n",
    "old_parsed['for_join'] = old_parsed.patient_id +'/'+ old_parsed.folder_1_last5 + '/' \\\n",
    "            + old_parsed.folder_2_last5 + '/' + old_parsed.image_name\n",
    "\n",
    "old_parsed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-training",
   "metadata": {},
   "source": [
    "Join these 2 together based on for_join column to get mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "polish-classroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8592, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mappings = fdf.merge(old_parsed[['for_join','old_image_filepath']],on='for_join',how='inner')\n",
    "train_mappings.to_csv(f'metadata/{mode}_set_path_mapping.csv',index=False)\n",
    "train_mappings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-merchant",
   "metadata": {},
   "source": [
    "Check to make sure there are 2 images MAX per directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "durable-petersburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fdf.groupby(['patient_id','folder_1','folder_2']).size() <= 2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-explanation",
   "metadata": {},
   "source": [
    "Move the pngs to the old filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "continental-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "urban-debate",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = f'/home/jupyter/data_png/cbis-ddsm-{mode}/cbis-ddsm-{mode}/'\n",
    "\n",
    "src_paths = train_mappings.fullpath.apply(lambda x: DATA_DIR + x.replace('.dcm','.png'))\n",
    "\n",
    "for p in Path(DATA_DIR).glob('**/*.png'):\n",
    "    if p.is_dir(): continue\n",
    "    \n",
    "    p_to_match = str(p)\n",
    "    \n",
    "    match_b = src_paths==p_to_match\n",
    "    if not match_b.any(): \n",
    "        print(p)\n",
    "        continue\n",
    "    path_to_mv_to = train_mappings.loc[match_b,'old_image_filepath'].iloc[0]\n",
    "    path_to_mv_to = Path('/home/jupyter/data_png_reorganized/' +  path_to_mv_to.replace('.dcm','.png'))\n",
    "    if not path_to_mv_to.parent.exists(): path_to_mv_to.parent.mkdir(parents=True)\n",
    "    if path_to_mv_to.exists(): path_to_mv_to.unlink()\n",
    "    shutil.copyfile(str(p), str(path_to_mv_to))\n",
    "    #p.replace(path_to_mv_to)\n",
    "    #path_to_mv_to.symlink_to(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-islam",
   "metadata": {},
   "source": [
    "Download to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "distinct-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_name = item.name\n",
    "blob = bucket.get_blob(blob_name)\n",
    "output_file_name = 'data/test_downloald.dcm'\n",
    "blob.download_to_filename(output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "narrative-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = open(output_file_name,'rb')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
